{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immediate bash output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "from IPython.core.magic import register_line_magic\n",
    "import sys\n",
    "\n",
    "@register_line_magic\n",
    "def runrealcmd(command):\n",
    "    print(command)\n",
    "    process = Popen(command, stdout=PIPE, shell=True, stderr=STDOUT, bufsize=1, close_fds=True)\n",
    "    for line in iter(process.stdout.readline, b''):\n",
    "        sys.stderr.write(line.decode('utf-8')+'\\r')\n",
    "    process.stdout.close()\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ping -c10 www.baidu.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PING www.a.shifen.com (182.61.200.7) 56(84) bytes of data.\n",
      "64 bytes from 182.61.200.7: icmp_seq=1 ttl=43 time=28.1 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=2 ttl=43 time=27.9 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=3 ttl=43 time=28.0 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=4 ttl=43 time=28.0 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=5 ttl=43 time=27.9 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=6 ttl=43 time=28.2 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=7 ttl=43 time=27.9 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=8 ttl=43 time=28.3 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=9 ttl=43 time=28.0 ms\n",
      "64 bytes from 182.61.200.7: icmp_seq=10 ttl=43 time=27.9 ms\n",
      "\n",
      "--- www.a.shifen.com ping statistics ---\n",
      "10 packets transmitted, 10 received, 0% packet loss, time 9012ms\n",
      "rtt min/avg/max/mdev = 27.908/28.060/28.395/0.269 ms\n"
     ]
    }
   ],
   "source": [
    "%runrealcmd ping -c10 www.baidu.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param changed:\n",
    "It's hard to run bash in jupyter with reasonable immediate result, so I run it in bash instead and copy the result here.\n",
    "\n",
    "- **train_batch_size:** 32 => 8\n",
    "- **max_seq_length:** 128 => 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data/CoLA \\\n",
    "--output_dir ./output/CoLA/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 8 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 3.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "06/15/2019 19:09:38 - INFO - __main__ -   ***** Eval results *****\n",
    "06/15/2019 19:09:38 - INFO - __main__ -     eval_loss = 0.5321744524568092\n",
    "06/15/2019 19:09:38 - INFO - __main__ -     global_step = 3207\n",
    "06/15/2019 19:09:38 - INFO - __main__ -     loss = 0.0745612160416827\n",
    "06/15/2019 19:09:38 - INFO - __main__ -     mcc = 0.5599614989717403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **num_train_epochs:** 3 => 10\n",
    "- let code use 3 GPUs - **FAILED** due to some bugs in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data/CoLA \\\n",
    "--output_dir ./output/CoLA2/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 8 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "06/15/2019 21:34:41 - INFO - __main__ -   ***** Eval results *****\n",
    "06/15/2019 21:34:41 - INFO - __main__ -     eval_loss = 0.8864743067449286\n",
    "06/15/2019 21:34:41 - INFO - __main__ -     global_step = 10690\n",
    "06/15/2019 21:34:41 - INFO - __main__ -     loss = 0.0077706406482558965\n",
    "06/15/2019 21:34:41 - INFO - __main__ -     mcc = 0.6056594364604692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **num_train_epochs:** 10 => 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data/CoLA \\\n",
    "--output_dir ./output/CoLA3/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 8 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 20.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "06/16/2019 00:59:14 - INFO - __main__ -   ***** Eval results *****\n",
    "06/16/2019 00:59:14 - INFO - __main__ -     eval_loss = 1.3830509036779404\n",
    "06/16/2019 00:59:14 - INFO - __main__ -     global_step = 21380\n",
    "06/16/2019 00:59:14 - INFO - __main__ -     loss = 0.00026008364263206034\n",
    "06/16/2019 00:59:14 - INFO - __main__ -     mcc = 0.616383370327138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Test the \"test mode\"\n",
    "- **num_train_epochs:** 20 => 3\n",
    "- **train_batch_size:** 8 => 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data/CoLA \\\n",
    "--output_dir ./output/CoLA4/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 20 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 3.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eval_loss = 0.5553696073079837\n",
    "global_step = 1284\n",
    "loss = 0.03563523098153303\n",
    "mcc = 0.6037743021259655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About STS\n",
    "- **train_batch_size:** 20 => 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-301d41bf5c5c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-301d41bf5c5c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python run_classifier.py \\\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data/STS-B \\\n",
    "--output_dir ./output/STSB/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 3.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### milestone\n",
    "(NOTICE! do not use ```tar``` to generate zip file)\n",
    "\n",
    "- CoLA - 57.1\n",
    "- STSB - 86.8/85.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- new data_dir glue_data_all includes all dev into train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoLA\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data_all/CoLA \\\n",
    "--output_dir ./output/CoLA5/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STS-B\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data_all/STS-B \\\n",
    "--output_dir ./output/STSB2/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CoLA-58.1, STSB-87.2-86.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoLA\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data_all/CoLA \\\n",
    "--output_dir ./output/CoLA6/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STS-B\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data_all/STS-B \\\n",
    "--output_dir ./output/STSB3/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CoLA-62.3, STSB-86.4-85.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implies:\n",
    "- CoLA only need limited training\n",
    "- STSB needs more\n",
    "- CoLA is well enough to compare with sembert\n",
    "\n",
    "What if we do not use all data\n",
    "- **num_train_epochs** changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# CoLA\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data/CoLA \\\n",
    "--output_dir ./output/CoLA7/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 5.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case\n",
    "\n",
    "# STS-B\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data/STS-B \\\n",
    "--output_dir ./output/STSB4/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 20.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CoLA-60.9-STSB-86.9-86.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CoLA needs the dev set\n",
    "- STS-B needs more round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# CoLA\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data_all/CoLA \\\n",
    "--output_dir ./output/CoLA001/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 5e-6 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--seed 1234 \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case\n",
    "\n",
    "# STS-B\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data_all/STS-B \\\n",
    "--output_dir ./output/STSB001/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--seed 1234 \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CoLA-60.0-STSB-87.8-86.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best one for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoLA\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name CoLA \\\n",
    "--data_dir ./data/glue_data_all/CoLA \\\n",
    "--output_dir ./output/CoLA6/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case\n",
    "\n",
    "# STS-B\n",
    "\n",
    "python run_classifier.py \\\n",
    "--task_name sts-b \\\n",
    "--data_dir ./data/glue_data_all/STS-B \\\n",
    "--output_dir ./output/STSB001/ \\\n",
    "--max_seq_length 64 \\\n",
    "--train_batch_size 24 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 10.0 \\\n",
    "--bert_model bert-large-uncased \\\n",
    "--seed 1234 \\\n",
    "--do_train --do_eval --do_test \\\n",
    "--do_lower_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLNet release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
